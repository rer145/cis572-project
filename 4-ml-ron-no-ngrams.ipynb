{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path_to_csv = './data/'\n",
    "csvs = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "#csvs = ['knitting.csv']\n",
    "csv_dict = dict()\n",
    "for page in csvs:\n",
    "    #url = \"https://raw.githubusercontent.com/rer145/cis572-project/master/data/\"+str(page)+\".csv\"\n",
    "    #raw_data = requests.get(url).content\n",
    "    #df = pd.read_csv(io.StringIO(raw_data.decode('utf-8')))\n",
    "    df = pd.read_csv(path_to_csv + page)\n",
    "    csv_dict[page] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that aren't predictive\n",
    "# remove columns that are ngrams\n",
    "for key in csv_dict.keys():\n",
    "    csv_dict[key].drop('post_gilded', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_silver', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_gold', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_platinum', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_likes', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_comments', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_crossposts', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_reports', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_ups', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_downs', axis=1, inplace=True)\n",
    "    \n",
    "    cols = [col for col in csv_dict[key].columns if '*' in col]\n",
    "    csv_dict[key].drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_score', 'post_archived', 'post_distinguished', 'post_edited',\n",
       "       'post_is_original_content', 'post_is_video', 'post_over_18',\n",
       "       'post_pinned', 'subreddit', 'subreddit_subscribers',\n",
       "       'posted_len_minutes', 'post_title_sentiment', 'post_title_characters',\n",
       "       'post_title_words', 'post_title_uniq_words', 'post_title_stop_words',\n",
       "       'post_title_non_stop_words', 'post_text_sentiment',\n",
       "       'post_text_characters', 'post_text_words', 'post_text_uniq_words',\n",
       "       'post_text_stop_words', 'post_text_non_stop_words', 'day_of_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dict['knitting.csv'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askmen.csv\n",
      "['post_archived', 'post_is_original_content', 'post_is_video', 'post_pinned', 'subreddit', 'subreddit_subscribers', 'day_of_week']\n",
      "\n",
      "askwomen.csv\n",
      "['post_archived', 'post_is_original_content', 'post_is_video', 'post_pinned', 'subreddit', 'day_of_week']\n",
      "\n",
      "aww-metadata.csv\n",
      "['post_archived', 'post_edited', 'post_over_18', 'post_pinned', 'subreddit', 'posted_len_minutes']\n",
      "\n",
      "aww-no-metadata.csv\n",
      "['post_archived', 'post_edited', 'post_over_18', 'post_pinned', 'subreddit', 'posted_len_minutes', 'post_text_sentiment', 'post_text_characters', 'post_text_words', 'post_text_uniq_words', 'post_text_stop_words', 'post_text_non_stop_words', 'day_of_week']\n",
      "\n",
      "aww.csv\n",
      "['post_archived', 'post_edited', 'post_over_18', 'post_pinned', 'subreddit', 'posted_len_minutes', 'post_text_sentiment', 'post_text_characters', 'post_text_words', 'post_text_uniq_words', 'post_text_stop_words', 'post_text_non_stop_words', 'day_of_week']\n",
      "\n",
      "conspiracy.csv\n",
      "['post_archived', 'post_is_original_content', 'post_is_video', 'post_pinned', 'subreddit', 'subreddit_subscribers', 'day_of_week']\n",
      "\n",
      "fitness.csv\n",
      "['post_archived', 'post_is_original_content', 'post_is_video', 'post_over_18', 'post_pinned', 'subreddit', 'day_of_week']\n",
      "\n",
      "knitting.csv\n",
      "['post_archived', 'post_is_original_content', 'post_pinned', 'subreddit', 'subreddit_subscribers', 'day_of_week']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove columns that only have a singular value\n",
    "for key in csv_dict.keys():\n",
    "    unique = [c for c in csv_dict[key].columns if len(set(csv_dict[key][c])) == 1]\n",
    "    print(key)\n",
    "    print(unique)\n",
    "    print()\n",
    "    csv_dict[key].drop(unique, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing askmen.csv\n",
      "parsing askwomen.csv\n",
      "parsing aww-metadata.csv\n",
      "parsing aww-no-metadata.csv\n",
      "parsing aww.csv\n",
      "parsing conspiracy.csv\n",
      "parsing fitness.csv\n",
      "parsing knitting.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for key in csv_dict.keys():\n",
    "    print('parsing', key)\n",
    "    #Change post_distinguished to numerical values, only None and Moderator values\n",
    "    if 'post_distinguished' in csv_dict[key]:\n",
    "        csv_dict[key]['post_distinguished'] = csv_dict[key]['post_distinguished'].map({None: 0, 'moderator': 1})\n",
    "        \n",
    "    #Mark edited posts with a 1\n",
    "    if 'post_edited' in csv_dict[key]:\n",
    "        csv_dict[key]['post_edited'] = (csv_dict[key]['post_edited'] == 'False')*1\n",
    "        \n",
    "    #Make post_over_18 binary\n",
    "    if 'post_over_18' in csv_dict[key]:\n",
    "        csv_dict[key]['post_over_18'] = csv_dict[key]['post_over_18'].astype('category').cat.codes\n",
    "        \n",
    "    #csv_dict[key] = csv_dict[key].dropna(csv_dict[key].median())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit: askmen.csv \t Number of popular posts: 248 \t Popular score cutoff: 19\n",
      "Subreddit: askwomen.csv \t Number of popular posts: 248 \t Popular score cutoff: 21\n",
      "Subreddit: aww-metadata.csv \t Number of popular posts: 247 \t Popular score cutoff: 36\n",
      "Subreddit: aww-no-metadata.csv \t Number of popular posts: 247 \t Popular score cutoff: 36\n",
      "Subreddit: aww.csv \t Number of popular posts: 247 \t Popular score cutoff: 36\n",
      "Subreddit: conspiracy.csv \t Number of popular posts: 247 \t Popular score cutoff: 39\n",
      "Subreddit: fitness.csv \t Number of popular posts: 239 \t Popular score cutoff: 14\n",
      "Subreddit: knitting.csv \t Number of popular posts: 249 \t Popular score cutoff: 112\n"
     ]
    }
   ],
   "source": [
    "for key in csv_dict.keys():\n",
    "    csv_dict[key] = csv_dict[key].sort_values('post_score', ascending=False)\n",
    "    cutoff_pos = round(csv_dict[key].shape[0]*.25)\n",
    "    cutoff_score = csv_dict[key].iloc[cutoff_pos]['post_score']\n",
    "    print('Subreddit:',key,'\\t Number of popular posts:',cutoff_pos,'\\t Popular score cutoff:',int(cutoff_score))\n",
    "    \n",
    "    csv_dict[key].loc[csv_dict[key]['post_score'] >= cutoff_score, 'popular'] = 1\n",
    "    csv_dict[key].loc[csv_dict[key]['post_score'] < cutoff_score, 'popular'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    #remove cols\n",
    "    if 'post_score' in data.columns:\n",
    "        data.drop('post_score', axis=1, inplace=True)\n",
    "    \n",
    "    #split into test and training\n",
    "    X = data.drop('popular', axis=1)\n",
    "    y = data['popular']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "    \n",
    "    #split into validation and training\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=50)\n",
    "    \n",
    "    #scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    #print('Data sizes')\n",
    "    #print('X_train', X_train.shape)\n",
    "    #print('X_val', X_val.shape)\n",
    "    #print('X_test', X_test.shape)\n",
    "    #print('y_train', y_train.shape)\n",
    "    #print('y_val', y_val.shape)\n",
    "    #print('y_test', y_test.shape)\n",
    "    \n",
    "    #return data\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "classifiers = [dtc, rfc, gnb, knn, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Support Vector Classifer</th>\n",
       "      <th>Hard Voting</th>\n",
       "      <th>Soft Voting</th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>askmen.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>askwomen.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww-metadata.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww-no-metadata.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # Instances # Features Decision Tree Random Forest  \\\n",
       "askmen.csv                  NaN        NaN           NaN           NaN   \n",
       "askwomen.csv                NaN        NaN           NaN           NaN   \n",
       "aww-metadata.csv            NaN        NaN           NaN           NaN   \n",
       "aww-no-metadata.csv         NaN        NaN           NaN           NaN   \n",
       "aww.csv                     NaN        NaN           NaN           NaN   \n",
       "\n",
       "                    Gaussian Naive Bayes K-Nearest Neighbors  \\\n",
       "askmen.csv                           NaN                 NaN   \n",
       "askwomen.csv                         NaN                 NaN   \n",
       "aww-metadata.csv                     NaN                 NaN   \n",
       "aww-no-metadata.csv                  NaN                 NaN   \n",
       "aww.csv                              NaN                 NaN   \n",
       "\n",
       "                    Support Vector Classifer Hard Voting Soft Voting Bagging  \n",
       "askmen.csv                               NaN         NaN         NaN     NaN  \n",
       "askwomen.csv                             NaN         NaN         NaN     NaN  \n",
       "aww-metadata.csv                         NaN         NaN         NaN     NaN  \n",
       "aww-no-metadata.csv                      NaN         NaN         NaN     NaN  \n",
       "aww.csv                                  NaN         NaN         NaN     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['Decision Tree', 'Random Forest', 'Gaussian Naive Bayes', 'K-Nearest Neighbors', 'Support Vector Classifer']\n",
    "cols = ['# Instances', '# Features'] + names + ['Hard Voting', 'Soft Voting', 'Bagging']\n",
    "val_results = pd.DataFrame(index=csv_dict.keys(), columns=cols)\n",
    "val_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit: askmen.csv\n",
      "Subreddit: askwomen.csv\n",
      "Subreddit: aww-metadata.csv\n",
      "Subreddit: aww-no-metadata.csv\n",
      "Subreddit: aww.csv\n",
      "Subreddit: conspiracy.csv\n",
      "Subreddit: fitness.csv\n",
      "Subreddit: knitting.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for key in csv_dict.keys():\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(csv_dict[key])\n",
    "    print('Subreddit:', key)\n",
    "    for name, algo in zip(names, classifiers):\n",
    "        algo.fit(X_train, y_train)\n",
    "        pred = algo.predict(X_val)\n",
    "        \n",
    "        val_results.loc[key]['# Instances'] = X_train.shape[0]\n",
    "        val_results.loc[key]['# Features'] = X_train.shape[1]\n",
    "        val_results.loc[key][name] = round(accuracy_score(y_val, pred), 3)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Support Vector Classifer</th>\n",
       "      <th>Hard Voting</th>\n",
       "      <th>Soft Voting</th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>askmen.csv</th>\n",
       "      <td>633</td>\n",
       "      <td>16</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>askwomen.csv</th>\n",
       "      <td>633</td>\n",
       "      <td>17</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww-metadata.csv</th>\n",
       "      <td>631</td>\n",
       "      <td>833</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww-no-metadata.csv</th>\n",
       "      <td>631</td>\n",
       "      <td>10</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aww.csv</th>\n",
       "      <td>631</td>\n",
       "      <td>10</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conspiracy.csv</th>\n",
       "      <td>631</td>\n",
       "      <td>16</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fitness.csv</th>\n",
       "      <td>611</td>\n",
       "      <td>16</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knitting.csv</th>\n",
       "      <td>636</td>\n",
       "      <td>17</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # Instances # Features Decision Tree Random Forest  \\\n",
       "askmen.csv                  633         16         0.572         0.704   \n",
       "askwomen.csv                633         17         0.667         0.698   \n",
       "aww-metadata.csv            631        833         0.703         0.734   \n",
       "aww-no-metadata.csv         631         10         0.557         0.684   \n",
       "aww.csv                     631         10         0.576         0.639   \n",
       "conspiracy.csv              631         16         0.582         0.709   \n",
       "fitness.csv                 611         16          0.66         0.791   \n",
       "knitting.csv                636         17          0.65         0.675   \n",
       "\n",
       "                    Gaussian Naive Bayes K-Nearest Neighbors  \\\n",
       "askmen.csv                         0.767               0.711   \n",
       "askwomen.csv                       0.698               0.654   \n",
       "aww-metadata.csv                   0.405               0.677   \n",
       "aww-no-metadata.csv                0.703               0.671   \n",
       "aww.csv                            0.703               0.671   \n",
       "conspiracy.csv                     0.241               0.715   \n",
       "fitness.csv                        0.745               0.706   \n",
       "knitting.csv                        0.55               0.694   \n",
       "\n",
       "                    Support Vector Classifer Hard Voting Soft Voting Bagging  \n",
       "askmen.csv                             0.767         NaN         NaN     NaN  \n",
       "askwomen.csv                           0.755         NaN         NaN     NaN  \n",
       "aww-metadata.csv                       0.753         NaN         NaN     NaN  \n",
       "aww-no-metadata.csv                    0.759         NaN         NaN     NaN  \n",
       "aww.csv                                0.759         NaN         NaN     NaN  \n",
       "conspiracy.csv                         0.753         NaN         NaN     NaN  \n",
       "fitness.csv                            0.758         NaN         NaN     NaN  \n",
       "knitting.csv                            0.75         NaN         NaN     NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
