{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./data/askwomen.csv', low_memory=False)\n",
    "#df['post_score'].describe()[6]\n",
    "#df.sort_values(by='post_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['post_score'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['post_score']] = scaler.fit_transform(df[['post_score']])\n",
    "#df['post_score'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = './data/'\n",
    "csvs = [pos_csv for pos_csv in os.listdir(path_to_csv) if pos_csv.endswith('.csv')]\n",
    "csvs = ['askwomen.csv']\n",
    "csv_dict = dict()\n",
    "for page in csvs:\n",
    "    #url = \"https://raw.githubusercontent.com/rer145/cis572-project/master/data/\"+str(page)+\".csv\"\n",
    "    #raw_data = requests.get(url).content\n",
    "    #df = pd.read_csv(io.StringIO(raw_data.decode('utf-8')))\n",
    "    df = pd.read_csv(path_to_csv + page, low_memory=False)\n",
    "    csv_dict[page] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that aren't predictive\n",
    "for key in csv_dict.keys():\n",
    "    csv_dict[key].drop('post_gilded', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_silver', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_gold', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_gilded_platinum', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_likes', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_comments', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_crossposts', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_num_reports', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_ups', axis=1, inplace=True)\n",
    "    csv_dict[key].drop('post_downs', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askwomen.csv\n",
      "['post_archived', 'post_is_original_content', 'post_is_video', 'post_pinned', 'subreddit', 'day_of_week']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove columns that only have a singular value\n",
    "for key in csv_dict.keys():\n",
    "    unique = [c for c in csv_dict[key].columns if len(set(csv_dict[key][c])) == 1]\n",
    "    print(key)\n",
    "    print(unique)\n",
    "    print()\n",
    "    csv_dict[key].drop(unique, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing askwomen.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for key in csv_dict.keys():\n",
    "    print('parsing', key)\n",
    "    #Change post_distinguished to numerical values, only None and Moderator values\n",
    "    if 'post_distinguished' in csv_dict[key]:\n",
    "        csv_dict[key]['post_distinguished'] = csv_dict[key]['post_distinguished'].map({None: 0, 'moderator': 1})\n",
    "        \n",
    "    #Mark edited posts with a 1\n",
    "    if 'post_edited' in csv_dict[key]:\n",
    "        csv_dict[key]['post_edited'] = (csv_dict[key]['post_edited'] == 'False')*1\n",
    "        \n",
    "    #Make post_over_18 binary\n",
    "    if 'post_over_18' in csv_dict[key]:\n",
    "        csv_dict[key]['post_over_18'] = csv_dict[key]['post_over_18'].astype('category').cat.codes\n",
    "        \n",
    "    #csv_dict[key] = csv_dict[key].dropna(csv_dict[key].median())\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in csv_dict.keys():\n",
    "#    csv_dict[key] = csv_dict[key].sort_values('post_score', ascending=False)\n",
    "#    cutoff_pos = round(csv_dict[key].shape[0]*.25)\n",
    "#    cutoff_score = csv_dict[key].iloc[cutoff_pos]['post_score']\n",
    "#    print('Subreddit:',key,'\\t Number of popular posts:',cutoff_pos,'\\t Popular score cutoff:',int(cutoff_score))\n",
    "    \n",
    "#    csv_dict[key].loc[csv_dict[key]['post_score'] >= cutoff_score, 'popular'] = 1\n",
    "#    csv_dict[key].loc[csv_dict[key]['post_score'] < cutoff_score, 'popular'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def is_popular(s):\n",
    "#    return s >= min_popular_score###\n",
    "\n",
    "#for key in csv_dict.keys():\n",
    "#    df = csv_dict[key]\n",
    "#    df[['post_score']] = scaler.fit_transform(df[['post_score']])\n",
    "#    \n",
    "###    max_post_score = max(df['post_score'])\n",
    "#    min_popular_score = max_post_score * .25#\n",
    "\n",
    "    #print(key)\n",
    "    #print('Highest Scoring Post', max_post_score)\n",
    "    #print('Min Post Score (Top 25%)', min_popular_score)\n",
    "    #print()\n",
    "\n",
    "    #df['popular'] = df['post_score'].apply(is_popular)\n",
    "    #df.loc[df['post_score'] >= min_popular_score -100]\n",
    "    \n",
    "    #csv_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in csv_dict.keys():\n",
    "    cutoff_score = csv_dict[key]['post_score'].describe()[6]\n",
    "    csv_dict[key].loc[csv_dict[key]['post_score'] >= cutoff_score, 'popular'] = 1\n",
    "    csv_dict[key].loc[csv_dict[key]['post_score'] < cutoff_score, 'popular'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \n",
    "    print(data.groupby(by='popular')['post_title_words'].count())\n",
    "    \n",
    "    \n",
    "    #remove cols\n",
    "    if 'post_score' in data.columns:\n",
    "        data.drop('post_score', axis=1, inplace=True)\n",
    "    \n",
    "    #split into test and training\n",
    "    X = data.drop('popular', axis=1)\n",
    "    y = data['popular']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    #print('First split of data')\n",
    "    #print('X_train', X_train.shape)\n",
    "    #print('X_test', X_test.shape)\n",
    "    #print('y_train', y_train.shape)\n",
    "    #print('y_test', y_test.shape)\n",
    "    \n",
    "    #split into validation and training\n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    #print('Second split of data')\n",
    "    #print('X_train', X_train.shape)\n",
    "    #print('X_val', X_val.shape)\n",
    "    #print('y_train', y_train.shape)\n",
    "    #print('y_val', y_val.shape)\n",
    "    \n",
    "    #scale the data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    #X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    #print('Data sizes')\n",
    "    #print('X_train', X_train.shape)\n",
    "    #print('X_val', X_val.shape)\n",
    "    #print('X_test', X_test.shape)\n",
    "    #print('y_train', y_train.shape)\n",
    "    #print('y_val', y_val.shape)\n",
    "    #print('y_test', y_test.shape)\n",
    "    \n",
    "    #return data\n",
    "    #return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askwomen.csv\n",
      "popular\n",
      "0.0    740\n",
      "1.0    251\n",
      "Name: post_title_words, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in csv_dict.keys():\n",
    "    print(key)\n",
    "    X_train, X_test, y_train, y_test = prepare_data(csv_dict[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "classifiers = [dtc, rfc, gnb, knn, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Support Vector Classifer</th>\n",
       "      <th>Hard Voting</th>\n",
       "      <th>Soft Voting</th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>askwomen.csv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             # Instances # Features Decision Tree Random Forest  \\\n",
       "askwomen.csv         NaN        NaN           NaN           NaN   \n",
       "\n",
       "             Gaussian Naive Bayes K-Nearest Neighbors  \\\n",
       "askwomen.csv                  NaN                 NaN   \n",
       "\n",
       "             Support Vector Classifer Hard Voting Soft Voting Bagging  \n",
       "askwomen.csv                      NaN         NaN         NaN     NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['Decision Tree', 'Random Forest', 'Gaussian Naive Bayes', 'K-Nearest Neighbors', 'Support Vector Classifer']\n",
    "cols = ['# Instances', '# Features'] + names + ['Hard Voting', 'Soft Voting', 'Bagging']\n",
    "val_results = pd.DataFrame(index=csv_dict.keys(), columns=cols)\n",
    "val_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular\n",
      "0.0    740\n",
      "1.0    251\n",
      "Name: post_title_words, dtype: int64\n",
      "Subreddit: askwomen.csv\n",
      "Decision Tree\n",
      "tn, fp, fn, tp\n",
      "112 37 38 12\n",
      "Random Forest\n",
      "tn, fp, fn, tp\n",
      "149 0 50 0\n",
      "Gaussian Naive Bayes\n",
      "tn, fp, fn, tp\n",
      "29 120 9 41\n",
      "K-Nearest Neighbors\n",
      "tn, fp, fn, tp\n",
      "149 0 50 0\n",
      "Support Vector Classifer\n",
      "tn, fp, fn, tp\n",
      "149 0 50 0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#accuracy_scores = []\n",
    "\n",
    "for key in csv_dict.keys():\n",
    "    #X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(csv_dict[key])\n",
    "    X_train, X_test, y_train, y_test = prepare_data(csv_dict[key])\n",
    "    print('Subreddit:', key)\n",
    "    #print()\n",
    "    #accuracy_scores = []\n",
    "    for name, algo in zip(names, classifiers):\n",
    "    #for algo in classifiers:\n",
    "        #if sum([1 for x in list(y_val) if x is True]) > 0 and sum([1 for x in list(y_val) if x is False]) > 0:\n",
    "        #if len(set(y_val.values)) == 2:\n",
    "        if len(set(y_test.values)) == 2:\n",
    "            algo.fit(X_train, y_train)\n",
    "            #pred = algo.predict(X_val)\n",
    "            pred = algo.predict(X_test)\n",
    "\n",
    "            val_results.loc[key]['# Instances'] = X_train.shape[0]\n",
    "            val_results.loc[key]['# Features'] = X_train.shape[1]\n",
    "            #val_results.loc[key][name] = round(accuracy_score(y_val, pred), 3)\n",
    "            val_results.loc[key][name] = round(accuracy_score(y_test, pred), 3)\n",
    "            \n",
    "            \n",
    "            print(name)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "            print('tn, fp, fn, tp')\n",
    "            print(tn, fp, fn, tp)\n",
    "\n",
    "        #print(name, '\\n')\n",
    "        #print('Accuracy score:', accuracy_score(y_val, pred))\n",
    "        #accuracy_scores.append(round(accuracy_score(y_val, pred),3))\n",
    "        #print('F1 score:', f1_score(y_val, pred))\n",
    "        #print('Precision score:', precision_score(y_val, pred))\n",
    "        #print('Recall score:', recall_score(y_val, pred))\n",
    "        #print('ROC/AUC score:', roc_auc_score(y_val, pred))\n",
    "        #print()\n",
    "    #print()\n",
    "    #print('Min score:', min(accuracy_scores))\n",
    "    #print('Mean score:', mean(accuracy_scores))\n",
    "    #print('Max score:',max(accuracy_scores))\n",
    "    #print()\n",
    "    #print('-'*60)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Instances</th>\n",
       "      <th># Features</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Support Vector Classifer</th>\n",
       "      <th>Hard Voting</th>\n",
       "      <th>Soft Voting</th>\n",
       "      <th>Bagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>askwomen.csv</th>\n",
       "      <td>792</td>\n",
       "      <td>10868</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             # Instances # Features Decision Tree Random Forest  \\\n",
       "askwomen.csv         792      10868         0.648         0.749   \n",
       "\n",
       "             Gaussian Naive Bayes K-Nearest Neighbors  \\\n",
       "askwomen.csv                0.352               0.749   \n",
       "\n",
       "             Support Vector Classifer Hard Voting Soft Voting Bagging  \n",
       "askwomen.csv                    0.749         NaN         NaN     NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn, fp, fn, tp\n",
      "149 0 50 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
